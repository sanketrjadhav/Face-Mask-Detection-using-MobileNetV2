{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset\n",
    "\n",
    "For the dataset you can download various images from web with and without mask and put it in separate folder with name 'with_mask' and 'without_mask'. And then both folder has to moved in single folder named 'dataset' as I mentioned the folder name in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 224\n",
    "height = 224\n",
    "batch_size = 32\n",
    "data_dir = r\"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3692 files belonging to 2 classes.\n",
      "Using 2585 files for training.\n"
     ]
    }
   ],
   "source": [
    "training = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.3,\n",
    "    subset='training',\n",
    "    seed=123,\n",
    "    image_size=(height, width),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3692 files belonging to 2 classes.\n",
      "Using 1107 files for validation.\n"
     ]
    }
   ],
   "source": [
    "validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.3,\n",
    "    subset='validation',\n",
    "    seed=123,\n",
    "    image_size=(height, width),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the MobileNetv2 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "81/81 [==============================] - 983s 12s/step - loss: 0.8176 - accuracy: 0.8856 - val_loss: 3.7613 - val_accuracy: 0.6504\n",
      "Epoch 2/3\n",
      "81/81 [==============================] - 629s 8s/step - loss: 0.0347 - accuracy: 0.9862 - val_loss: 9.3884 - val_accuracy: 0.6125\n",
      "Epoch 3/3\n",
      "81/81 [==============================] - 609s 7s/step - loss: 0.0447 - accuracy: 0.9888 - val_loss: 1.4749 - val_accuracy: 0.8925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x243a5259370>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training,validation_data=validation,epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on a new unknown image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 224, 224, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the image\n",
    "img = tf.keras.preprocessing.image.load_img('new1.jpg', target_size=(height, width))\n",
    "#convert to array\n",
    "image_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "#expand dimensions to fit in the model\n",
    "image_array = tf.expand_dims(image_array,0)\n",
    "#check the shape of the image\n",
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(image_array)\n",
    "#using softmax to get the results\n",
    "score = tf.nn.softmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without_mask 0.2712135436013341\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(classes[numpy.argmax(score)], 100*numpy.max(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dummy.model', save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
